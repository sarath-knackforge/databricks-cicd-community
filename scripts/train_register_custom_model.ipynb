{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc324be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install model_deploy-0.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ..\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8434bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from loguru import logger\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.dbutils import DBUtils\n",
    "from importlib.metadata import version\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_deploy.config import ProjectConfig, Tags\n",
    "from model_deploy.models.basic_model import BasicModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.dbutils import DBUtils\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "dbutils = DBUtils(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a254c25",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/*\n",
    "CREATE TABLE IF NOT EXISTS mlops_dev.model_test.training_control (\n",
    "    allow_training BOOLEAN,\n",
    "    updated_on TIMESTAMP\n",
    ");\n",
    "\n",
    "INSERT INTO mlops_dev.model_test.training_control\n",
    "VALUES (true, current_timestamp());\n",
    "*/\n",
    "CREATE TABLE IF NOT EXISTS mlops_prod.model_test.training_control (\n",
    "    allow_training BOOLEAN,\n",
    "    updated_on TIMESTAMP\n",
    ");\n",
    "\n",
    "INSERT INTO mlops_prod.model_test.training_control\n",
    "VALUES (true, current_timestamp());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# PATCH BASICMODEL FOR SKLEARN DATASET\n",
    "# -----------------------------------------------------------\n",
    "def patch_basicmodel_for_sklearn():\n",
    "    \"\"\"Patch BasicModel.load_data() and BasicModel.prepare_features() \n",
    "       to use sklearn dataset instead of Delta tables.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_data(self):\n",
    "                # ----------------------------------------------------\n",
    "        # üîê TRAINING CONTROL CHECK\n",
    "        # ----------------------------------------------------\n",
    "        logger.info(\"üîç Checking training control flag in Lakehouse...\")\n",
    "\n",
    "        # flag = spark.sql(\"\"\"\n",
    "        #     SELECT allow_training\n",
    "        #     FROM mlops_prod.model_test.training_control\n",
    "        #     ORDER BY updated_on DESC\n",
    "        #     LIMIT 1\n",
    "        # \"\"\").first()[0]\n",
    "\n",
    "        #to disable training control check, uncomment below lines\n",
    "        # if not flag:\n",
    "        #     logger.warning(\"‚õî Training disabled via training_control table. Skipping training.\")\n",
    "        #     # Tell pipeline to skip\n",
    "        #     dbutils.jobs.taskValues.set(\"training_skipped\", \"TRUE\")\n",
    "        #     sys.exit(0)\n",
    "\n",
    "        logger.info(\"‚úÖ Training allowed ‚Äî proceeding with dataset loading.\")\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # LOAD SKLEARN DATASET\n",
    "        # ----------------------------------------------------\n",
    "        logger.info(\"üîÑ Loading sklearn breast cancer dataset...\")\n",
    "\n",
    "        data = load_breast_cancer()\n",
    "        df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "        df[\"target\"] = data.target\n",
    "\n",
    "        # ALL numeric features\n",
    "        self.num_features = list(df.columns)\n",
    "        self.num_features.remove(\"target\")\n",
    "\n",
    "        self.cat_features = []   # No categorical features\n",
    "\n",
    "        # Train/Test split\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.train_set = train_df\n",
    "        self.test_set = test_df\n",
    "\n",
    "        self.X_train = train_df[self.num_features]\n",
    "        self.y_train = train_df[\"target\"]\n",
    "        self.X_test = test_df[self.num_features]\n",
    "        self.y_test = test_df[\"target\"]\n",
    "\n",
    "        # Needed for model_improved()\n",
    "        self.eval_data = test_df.copy()\n",
    "\n",
    "        logger.info(\"‚úÖ sklearn dataset loaded successfully.\")\n",
    "\n",
    "    def prepare_features(self):\n",
    "        logger.info(\"üîÑ No preprocessing needed for sklearn dataset.\")\n",
    "        from lightgbm import LGBMClassifier\n",
    "        self.pipeline = LGBMClassifier(**self.parameters)\n",
    "        logger.info(\"‚úÖ Pipeline ready using LGBMClassifier.\")\n",
    "\n",
    "    def log_model(self):\n",
    "        logger.info(\"üì¶ Logging model + parameters + metrics to MLflow...\")\n",
    "\n",
    "        # mlflow.set_experiment(self.experiment_name)\n",
    "        mlflow.set_experiment(\"/Shared/mlops_exp\")\n",
    "\n",
    "        with mlflow.start_run(run_name=\"basic-lgbm\", tags=self.tags) as run:\n",
    "\n",
    "            # ‚≠ê save run_id for register_model()\n",
    "            self.run_id = run.info.run_id\n",
    "            dbutils.jobs.taskValues.set(\"candidate_run_id\", self.run_id)\n",
    "            # --- parameters ---\n",
    "            mlflow.log_params(self.config.parameters)\n",
    "\n",
    "            # --- metrics ---\n",
    "            y_pred = self.pipeline.predict(self.X_test)\n",
    "\n",
    "            self.metrics = {\n",
    "                \"f1_score\": float(f1_score(self.y_test, y_pred)),\n",
    "                \"accuracy\": float(accuracy_score(self.y_test, y_pred)),\n",
    "                \"precision\": float(precision_score(self.y_test, y_pred)),\n",
    "                \"recall\": float(recall_score(self.y_test, y_pred)),\n",
    "            }\n",
    "\n",
    "            mlflow.log_metrics(self.metrics)\n",
    "\n",
    "            # --- model artifact ---\n",
    "            logger.info(\"üìÅ Logging sklearn LightGBM model...\")\n",
    "            signature = infer_signature(self.X_train, self.pipeline.predict(self.X_train))\n",
    "\n",
    "            self.model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=self.pipeline,\n",
    "                artifact_path=\"model\",\n",
    "                signature=signature,\n",
    "                input_example=self.X_train.iloc[0:1],\n",
    "            )\n",
    "\n",
    "        logger.info(f\"‚úÖ MLflow logging completed. Run ID: {self.run_id}, Metrics: {self.metrics}\")\n",
    "\n",
    "\n",
    "        # Patch methods\n",
    "    BasicModel.load_data = load_data\n",
    "    BasicModel.prepare_features = prepare_features\n",
    "    BasicModel.log_model = log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2953394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# MANUAL RUN (NO ARGPARSE NEEDED)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "env = \"dev\"  # You can change manually: dev / acc / prd\n",
    "config_path = \"model_config_deploy.yml\"\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "dbutils = DBUtils(spark)\n",
    "\n",
    "# Manual tags for logging\n",
    "tags = Tags(\n",
    "    git_sha=\"manual_run\",\n",
    "    branch=\"manual_run\",\n",
    "    job_run_id=\"manual_run\"#spark.conf.get(\"spark.databricks.job.id\", \"unknown_job_id\")\n",
    ")\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=config_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Patch BEFORE running training\n",
    "patch_basicmodel_for_sklearn()\n",
    "print(config)\n",
    "basic_model = BasicModel(config=config, tags=tags, spark=spark)\n",
    "\n",
    "basic_model.load_data()\n",
    "basic_model.prepare_features()\n",
    "\n",
    "basic_model.train()\n",
    "basic_model.log_model()\n",
    "\n",
    "model_improved = basic_model.model_improved() # Ensure the model alias exists before calling model_improved, or handle the case where it does not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "#  REGISTER MODEL (COMMUNITY + UC-SAFE WAY)\n",
    "# -----------------------------------------------------------\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "\n",
    "# ‚úÖ Use the run_id we stored during log_model()\n",
    "run_id = basic_model.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# üëâ IMPORTANT: use a NEW model name (avoid existing model_deploy that you lack rights on)\n",
    "MODEL_NAME = \"workspace.default.breast_cancer_lgbm\"\n",
    "\n",
    "print(f\"üì¶ Registering model_uri={model_uri} as {MODEL_NAME} ...\")\n",
    "\n",
    "try:\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=MODEL_NAME,\n",
    "    )\n",
    "    print(\"‚úÖ Model successfully REGISTERED\")\n",
    "    print(\"‚úÖ Registered model:\", result.name)\n",
    "    print(\"‚úÖ Registered version:\", result.version)\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"‚ùå Registration failed: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "#  LOAD THE JUST-REGISTERED VERSION\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Use the version we just created instead of hardcoding \"1\"\n",
    "MODEL_VERSION = result.version\n",
    "\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# Verify model is visible\n",
    "rm = client.get_registered_model(MODEL_NAME)\n",
    "print(\"‚úÖ Registered model found:\", rm.name)\n",
    "\n",
    "MODEL_URI = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "print(\"‚úÖ Final Model URI:\", MODEL_URI)\n",
    "\n",
    "model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "print(\"‚úÖ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b2b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "# run_id = mlflow.last_active_run().info.run_id\n",
    "# model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# mlflow.register_model(\n",
    "#     model_uri=model_uri,\n",
    "#     name=\"model_deploy\"\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ Model successfully REGISTERED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# from mlflow import MlflowClient\n",
    "\n",
    "# # ‚úÖ Always force Databricks tracking\n",
    "# mlflow.set_tracking_uri(\"databricks\")\n",
    "\n",
    "# client = MlflowClient()\n",
    "\n",
    "# # ‚úÖ Your ACTUAL registered model (confirmed by your output)\n",
    "# # MODEL_NAME = \"workspace.default.model_deploy\"\n",
    "# MODEL_NAME = \"workspace.default.breast_cancer_lgbm\"\n",
    "# MODEL_VERSION = \"1\"\n",
    "\n",
    "# print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # ‚úÖ 1. Verify registered model exists\n",
    "# # --------------------------------------------------------\n",
    "# try:\n",
    "#     rm = client.get_registered_model(MODEL_NAME)\n",
    "#     print(\"‚úÖ Registered model found:\", rm.name)\n",
    "# except Exception as e:\n",
    "#     raise SystemExit(f\"‚ùå Model not found: {e}\")\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # ‚úÖ 2. Build UC-compatible model URI (NO FILTER, NO ALIAS)\n",
    "# # --------------------------------------------------------\n",
    "# MODEL_URI = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "# print(\"‚úÖ Final Model URI:\", MODEL_URI)\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # ‚úÖ 3. Load model for inference / deployment\n",
    "# # --------------------------------------------------------\n",
    "# model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "\n",
    "# print(\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# # --------------------------------------------------------\n",
    "# # ‚úÖ 4. (Optional) Test prediction\n",
    "# # --------------------------------------------------------\n",
    "# # preds = model.predict(test_dataframe)\n",
    "# # print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
